{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 14089,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007097735822272695,
      "grad_norm": 2.698746681213379,
      "learning_rate": 4.966640641635318e-05,
      "loss": 3.9602,
      "step": 100
    },
    {
      "epoch": 0.01419547164454539,
      "grad_norm": 2.101531744003296,
      "learning_rate": 4.931151962523955e-05,
      "loss": 0.6932,
      "step": 200
    },
    {
      "epoch": 0.021293207466818086,
      "grad_norm": 0.9181289672851562,
      "learning_rate": 4.895663283412591e-05,
      "loss": 0.5059,
      "step": 300
    },
    {
      "epoch": 0.02839094328909078,
      "grad_norm": 2.295689582824707,
      "learning_rate": 4.8601746043012284e-05,
      "loss": 0.434,
      "step": 400
    },
    {
      "epoch": 0.035488679111363476,
      "grad_norm": 1.333854079246521,
      "learning_rate": 4.824685925189865e-05,
      "loss": 0.3906,
      "step": 500
    },
    {
      "epoch": 0.04258641493363617,
      "grad_norm": 1.0300284624099731,
      "learning_rate": 4.7891972460785014e-05,
      "loss": 0.337,
      "step": 600
    },
    {
      "epoch": 0.04968415075590887,
      "grad_norm": 0.7704614996910095,
      "learning_rate": 4.753708566967138e-05,
      "loss": 0.3421,
      "step": 700
    },
    {
      "epoch": 0.05678188657818156,
      "grad_norm": 1.5077900886535645,
      "learning_rate": 4.718219887855774e-05,
      "loss": 0.334,
      "step": 800
    },
    {
      "epoch": 0.06387962240045425,
      "grad_norm": 0.8445001244544983,
      "learning_rate": 4.682731208744411e-05,
      "loss": 0.3049,
      "step": 900
    },
    {
      "epoch": 0.07097735822272695,
      "grad_norm": 1.422363519668579,
      "learning_rate": 4.647242529633047e-05,
      "loss": 0.3348,
      "step": 1000
    },
    {
      "epoch": 0.07807509404499964,
      "grad_norm": 1.354095697402954,
      "learning_rate": 4.611753850521684e-05,
      "loss": 0.2955,
      "step": 1100
    },
    {
      "epoch": 0.08517282986727234,
      "grad_norm": 1.5589709281921387,
      "learning_rate": 4.57626517141032e-05,
      "loss": 0.3124,
      "step": 1200
    },
    {
      "epoch": 0.09227056568954503,
      "grad_norm": 0.7726919054985046,
      "learning_rate": 4.5407764922989574e-05,
      "loss": 0.2733,
      "step": 1300
    },
    {
      "epoch": 0.09936830151181773,
      "grad_norm": 0.9298578500747681,
      "learning_rate": 4.505287813187594e-05,
      "loss": 0.288,
      "step": 1400
    },
    {
      "epoch": 0.10646603733409042,
      "grad_norm": 1.0311036109924316,
      "learning_rate": 4.4697991340762297e-05,
      "loss": 0.2847,
      "step": 1500
    },
    {
      "epoch": 0.11356377315636312,
      "grad_norm": 1.4733365774154663,
      "learning_rate": 4.434310454964866e-05,
      "loss": 0.2992,
      "step": 1600
    },
    {
      "epoch": 0.12066150897863581,
      "grad_norm": 0.9774875640869141,
      "learning_rate": 4.3988217758535026e-05,
      "loss": 0.2859,
      "step": 1700
    },
    {
      "epoch": 0.1277592448009085,
      "grad_norm": 0.7976555228233337,
      "learning_rate": 4.363333096742139e-05,
      "loss": 0.2617,
      "step": 1800
    },
    {
      "epoch": 0.13485698062318122,
      "grad_norm": 0.9290769100189209,
      "learning_rate": 4.3278444176307756e-05,
      "loss": 0.242,
      "step": 1900
    },
    {
      "epoch": 0.1419547164454539,
      "grad_norm": 1.2661371231079102,
      "learning_rate": 4.292355738519413e-05,
      "loss": 0.2401,
      "step": 2000
    },
    {
      "epoch": 0.1490524522677266,
      "grad_norm": 0.48718324303627014,
      "learning_rate": 4.256867059408049e-05,
      "loss": 0.2535,
      "step": 2100
    },
    {
      "epoch": 0.15615018808999928,
      "grad_norm": 1.2693711519241333,
      "learning_rate": 4.221378380296686e-05,
      "loss": 0.2672,
      "step": 2200
    },
    {
      "epoch": 0.163247923912272,
      "grad_norm": 0.8471925854682922,
      "learning_rate": 4.185889701185322e-05,
      "loss": 0.2463,
      "step": 2300
    },
    {
      "epoch": 0.17034565973454469,
      "grad_norm": 0.6046504974365234,
      "learning_rate": 4.1504010220739586e-05,
      "loss": 0.2326,
      "step": 2400
    },
    {
      "epoch": 0.17744339555681737,
      "grad_norm": 0.8854577541351318,
      "learning_rate": 4.114912342962595e-05,
      "loss": 0.2371,
      "step": 2500
    },
    {
      "epoch": 0.18454113137909006,
      "grad_norm": 0.6511681079864502,
      "learning_rate": 4.0794236638512316e-05,
      "loss": 0.2141,
      "step": 2600
    },
    {
      "epoch": 0.19163886720136278,
      "grad_norm": 1.152651071548462,
      "learning_rate": 4.043934984739868e-05,
      "loss": 0.2453,
      "step": 2700
    },
    {
      "epoch": 0.19873660302363547,
      "grad_norm": 1.9777731895446777,
      "learning_rate": 4.0084463056285046e-05,
      "loss": 0.2624,
      "step": 2800
    },
    {
      "epoch": 0.20583433884590815,
      "grad_norm": 1.0753995180130005,
      "learning_rate": 3.972957626517142e-05,
      "loss": 0.2418,
      "step": 2900
    },
    {
      "epoch": 0.21293207466818084,
      "grad_norm": 1.540812373161316,
      "learning_rate": 3.937468947405778e-05,
      "loss": 0.2416,
      "step": 3000
    },
    {
      "epoch": 0.22002981049045356,
      "grad_norm": 1.2997368574142456,
      "learning_rate": 3.901980268294415e-05,
      "loss": 0.2397,
      "step": 3100
    },
    {
      "epoch": 0.22712754631272625,
      "grad_norm": 1.3143391609191895,
      "learning_rate": 3.8664915891830505e-05,
      "loss": 0.2447,
      "step": 3200
    },
    {
      "epoch": 0.23422528213499894,
      "grad_norm": 1.2041455507278442,
      "learning_rate": 3.831002910071687e-05,
      "loss": 0.2374,
      "step": 3300
    },
    {
      "epoch": 0.24132301795727162,
      "grad_norm": 0.6605631709098816,
      "learning_rate": 3.7955142309603234e-05,
      "loss": 0.2235,
      "step": 3400
    },
    {
      "epoch": 0.2484207537795443,
      "grad_norm": 1.1569840908050537,
      "learning_rate": 3.76002555184896e-05,
      "loss": 0.2305,
      "step": 3500
    },
    {
      "epoch": 0.255518489601817,
      "grad_norm": 0.9257549047470093,
      "learning_rate": 3.724536872737597e-05,
      "loss": 0.2398,
      "step": 3600
    },
    {
      "epoch": 0.2626162254240897,
      "grad_norm": 0.7525496482849121,
      "learning_rate": 3.6890481936262335e-05,
      "loss": 0.2181,
      "step": 3700
    },
    {
      "epoch": 0.26971396124636243,
      "grad_norm": 1.511085867881775,
      "learning_rate": 3.65355951451487e-05,
      "loss": 0.2288,
      "step": 3800
    },
    {
      "epoch": 0.2768116970686351,
      "grad_norm": 1.2251003980636597,
      "learning_rate": 3.6180708354035065e-05,
      "loss": 0.2335,
      "step": 3900
    },
    {
      "epoch": 0.2839094328909078,
      "grad_norm": 1.4359149932861328,
      "learning_rate": 3.582582156292143e-05,
      "loss": 0.2264,
      "step": 4000
    },
    {
      "epoch": 0.2910071687131805,
      "grad_norm": 0.6429341435432434,
      "learning_rate": 3.5470934771807795e-05,
      "loss": 0.2199,
      "step": 4100
    },
    {
      "epoch": 0.2981049045354532,
      "grad_norm": 0.7954586148262024,
      "learning_rate": 3.511604798069416e-05,
      "loss": 0.212,
      "step": 4200
    },
    {
      "epoch": 0.3052026403577259,
      "grad_norm": 0.8426762819290161,
      "learning_rate": 3.4761161189580524e-05,
      "loss": 0.2134,
      "step": 4300
    },
    {
      "epoch": 0.31230037617999856,
      "grad_norm": 1.2749857902526855,
      "learning_rate": 3.4406274398466896e-05,
      "loss": 0.2473,
      "step": 4400
    },
    {
      "epoch": 0.31939811200227125,
      "grad_norm": 2.231255292892456,
      "learning_rate": 3.405138760735326e-05,
      "loss": 0.2254,
      "step": 4500
    },
    {
      "epoch": 0.326495847824544,
      "grad_norm": 1.077510952949524,
      "learning_rate": 3.3696500816239625e-05,
      "loss": 0.2366,
      "step": 4600
    },
    {
      "epoch": 0.3335935836468167,
      "grad_norm": 0.5365071892738342,
      "learning_rate": 3.334161402512599e-05,
      "loss": 0.2117,
      "step": 4700
    },
    {
      "epoch": 0.34069131946908937,
      "grad_norm": 1.0205503702163696,
      "learning_rate": 3.298672723401235e-05,
      "loss": 0.2259,
      "step": 4800
    },
    {
      "epoch": 0.34778905529136206,
      "grad_norm": 1.5200923681259155,
      "learning_rate": 3.263184044289871e-05,
      "loss": 0.2005,
      "step": 4900
    },
    {
      "epoch": 0.35488679111363475,
      "grad_norm": 0.6702759265899658,
      "learning_rate": 3.227695365178508e-05,
      "loss": 0.1961,
      "step": 5000
    },
    {
      "epoch": 0.36198452693590744,
      "grad_norm": 0.7486109733581543,
      "learning_rate": 3.192206686067144e-05,
      "loss": 0.2126,
      "step": 5100
    },
    {
      "epoch": 0.3690822627581801,
      "grad_norm": 1.1163474321365356,
      "learning_rate": 3.1567180069557814e-05,
      "loss": 0.2196,
      "step": 5200
    },
    {
      "epoch": 0.3761799985804528,
      "grad_norm": 1.0128570795059204,
      "learning_rate": 3.121229327844418e-05,
      "loss": 0.2024,
      "step": 5300
    },
    {
      "epoch": 0.38327773440272556,
      "grad_norm": 0.8127895593643188,
      "learning_rate": 3.0857406487330543e-05,
      "loss": 0.2089,
      "step": 5400
    },
    {
      "epoch": 0.39037547022499824,
      "grad_norm": 0.8640220165252686,
      "learning_rate": 3.0502519696216908e-05,
      "loss": 0.1999,
      "step": 5500
    },
    {
      "epoch": 0.39747320604727093,
      "grad_norm": 0.8150877356529236,
      "learning_rate": 3.0147632905103273e-05,
      "loss": 0.1989,
      "step": 5600
    },
    {
      "epoch": 0.4045709418695436,
      "grad_norm": 1.272007703781128,
      "learning_rate": 2.9792746113989638e-05,
      "loss": 0.2021,
      "step": 5700
    },
    {
      "epoch": 0.4116686776918163,
      "grad_norm": 0.8930953741073608,
      "learning_rate": 2.9437859322876006e-05,
      "loss": 0.2182,
      "step": 5800
    },
    {
      "epoch": 0.418766413514089,
      "grad_norm": 0.9354653358459473,
      "learning_rate": 2.908297253176237e-05,
      "loss": 0.1998,
      "step": 5900
    },
    {
      "epoch": 0.4258641493363617,
      "grad_norm": 1.5405594110488892,
      "learning_rate": 2.8728085740648736e-05,
      "loss": 0.2217,
      "step": 6000
    },
    {
      "epoch": 0.4329618851586344,
      "grad_norm": 1.9769232273101807,
      "learning_rate": 2.83731989495351e-05,
      "loss": 0.2143,
      "step": 6100
    },
    {
      "epoch": 0.4400596209809071,
      "grad_norm": 0.3800073564052582,
      "learning_rate": 2.801831215842147e-05,
      "loss": 0.2064,
      "step": 6200
    },
    {
      "epoch": 0.4471573568031798,
      "grad_norm": 0.6939185261726379,
      "learning_rate": 2.7663425367307833e-05,
      "loss": 0.1917,
      "step": 6300
    },
    {
      "epoch": 0.4542550926254525,
      "grad_norm": 1.0970754623413086,
      "learning_rate": 2.7308538576194198e-05,
      "loss": 0.2201,
      "step": 6400
    },
    {
      "epoch": 0.4613528284477252,
      "grad_norm": 0.8455415368080139,
      "learning_rate": 2.695365178508056e-05,
      "loss": 0.207,
      "step": 6500
    },
    {
      "epoch": 0.46845056426999787,
      "grad_norm": 0.7419204115867615,
      "learning_rate": 2.6598764993966924e-05,
      "loss": 0.1832,
      "step": 6600
    },
    {
      "epoch": 0.47554830009227056,
      "grad_norm": 1.7670776844024658,
      "learning_rate": 2.624387820285329e-05,
      "loss": 0.2135,
      "step": 6700
    },
    {
      "epoch": 0.48264603591454325,
      "grad_norm": 0.7383189797401428,
      "learning_rate": 2.5888991411739654e-05,
      "loss": 0.1911,
      "step": 6800
    },
    {
      "epoch": 0.48974377173681594,
      "grad_norm": 2.400174379348755,
      "learning_rate": 2.5534104620626022e-05,
      "loss": 0.1948,
      "step": 6900
    },
    {
      "epoch": 0.4968415075590886,
      "grad_norm": 2.3151426315307617,
      "learning_rate": 2.5179217829512387e-05,
      "loss": 0.1924,
      "step": 7000
    },
    {
      "epoch": 0.5039392433813613,
      "grad_norm": 0.7069321274757385,
      "learning_rate": 2.482433103839875e-05,
      "loss": 0.1969,
      "step": 7100
    },
    {
      "epoch": 0.511036979203634,
      "grad_norm": 0.3924514353275299,
      "learning_rate": 2.4469444247285116e-05,
      "loss": 0.2285,
      "step": 7200
    },
    {
      "epoch": 0.5181347150259067,
      "grad_norm": 0.6567626595497131,
      "learning_rate": 2.411455745617148e-05,
      "loss": 0.2029,
      "step": 7300
    },
    {
      "epoch": 0.5252324508481794,
      "grad_norm": 0.8408030271530151,
      "learning_rate": 2.375967066505785e-05,
      "loss": 0.1986,
      "step": 7400
    },
    {
      "epoch": 0.5323301866704522,
      "grad_norm": 1.6352304220199585,
      "learning_rate": 2.3404783873944214e-05,
      "loss": 0.2187,
      "step": 7500
    },
    {
      "epoch": 0.5394279224927249,
      "grad_norm": 0.6412705183029175,
      "learning_rate": 2.304989708283058e-05,
      "loss": 0.2221,
      "step": 7600
    },
    {
      "epoch": 0.5465256583149976,
      "grad_norm": 0.8836383819580078,
      "learning_rate": 2.2695010291716944e-05,
      "loss": 0.2075,
      "step": 7700
    },
    {
      "epoch": 0.5536233941372702,
      "grad_norm": 1.0986459255218506,
      "learning_rate": 2.234012350060331e-05,
      "loss": 0.2088,
      "step": 7800
    },
    {
      "epoch": 0.5607211299595429,
      "grad_norm": 0.9835798144340515,
      "learning_rate": 2.1985236709489673e-05,
      "loss": 0.2099,
      "step": 7900
    },
    {
      "epoch": 0.5678188657818156,
      "grad_norm": 0.32711315155029297,
      "learning_rate": 2.1630349918376038e-05,
      "loss": 0.1864,
      "step": 8000
    },
    {
      "epoch": 0.5749166016040883,
      "grad_norm": 1.737251877784729,
      "learning_rate": 2.1275463127262403e-05,
      "loss": 0.1782,
      "step": 8100
    },
    {
      "epoch": 0.582014337426361,
      "grad_norm": 1.5272853374481201,
      "learning_rate": 2.0924125204059904e-05,
      "loss": 0.2002,
      "step": 8200
    },
    {
      "epoch": 0.5891120732486337,
      "grad_norm": 0.9884978532791138,
      "learning_rate": 2.056923841294627e-05,
      "loss": 0.189,
      "step": 8300
    },
    {
      "epoch": 0.5962098090709064,
      "grad_norm": 0.49723461270332336,
      "learning_rate": 2.0214351621832636e-05,
      "loss": 0.1967,
      "step": 8400
    },
    {
      "epoch": 0.6033075448931791,
      "grad_norm": 0.7490780353546143,
      "learning_rate": 1.9859464830719e-05,
      "loss": 0.1967,
      "step": 8500
    },
    {
      "epoch": 0.6104052807154517,
      "grad_norm": 0.8191527128219604,
      "learning_rate": 1.9504578039605366e-05,
      "loss": 0.1886,
      "step": 8600
    },
    {
      "epoch": 0.6175030165377244,
      "grad_norm": 0.9200625419616699,
      "learning_rate": 1.9149691248491734e-05,
      "loss": 0.1855,
      "step": 8700
    },
    {
      "epoch": 0.6246007523599971,
      "grad_norm": 0.9547176957130432,
      "learning_rate": 1.87948044573781e-05,
      "loss": 0.196,
      "step": 8800
    },
    {
      "epoch": 0.6316984881822698,
      "grad_norm": 0.6516028046607971,
      "learning_rate": 1.843991766626446e-05,
      "loss": 0.207,
      "step": 8900
    },
    {
      "epoch": 0.6387962240045425,
      "grad_norm": 0.8859260082244873,
      "learning_rate": 1.8085030875150825e-05,
      "loss": 0.2095,
      "step": 9000
    },
    {
      "epoch": 0.6458939598268153,
      "grad_norm": 1.0931504964828491,
      "learning_rate": 1.7730144084037193e-05,
      "loss": 0.1804,
      "step": 9100
    },
    {
      "epoch": 0.652991695649088,
      "grad_norm": 0.9494006633758545,
      "learning_rate": 1.7375257292923558e-05,
      "loss": 0.1911,
      "step": 9200
    },
    {
      "epoch": 0.6600894314713607,
      "grad_norm": 0.499126136302948,
      "learning_rate": 1.7020370501809923e-05,
      "loss": 0.1849,
      "step": 9300
    },
    {
      "epoch": 0.6671871672936334,
      "grad_norm": 1.316665530204773,
      "learning_rate": 1.6665483710696288e-05,
      "loss": 0.1848,
      "step": 9400
    },
    {
      "epoch": 0.674284903115906,
      "grad_norm": 0.449942409992218,
      "learning_rate": 1.6310596919582656e-05,
      "loss": 0.2008,
      "step": 9500
    },
    {
      "epoch": 0.6813826389381787,
      "grad_norm": 0.9265688061714172,
      "learning_rate": 1.595571012846902e-05,
      "loss": 0.196,
      "step": 9600
    },
    {
      "epoch": 0.6884803747604514,
      "grad_norm": 1.067348837852478,
      "learning_rate": 1.5600823337355382e-05,
      "loss": 0.1764,
      "step": 9700
    },
    {
      "epoch": 0.6955781105827241,
      "grad_norm": 1.22455632686615,
      "learning_rate": 1.5245936546241749e-05,
      "loss": 0.1918,
      "step": 9800
    },
    {
      "epoch": 0.7026758464049968,
      "grad_norm": 0.6763055324554443,
      "learning_rate": 1.4891049755128115e-05,
      "loss": 0.2041,
      "step": 9900
    },
    {
      "epoch": 0.7097735822272695,
      "grad_norm": 0.8202647566795349,
      "learning_rate": 1.453616296401448e-05,
      "loss": 0.1927,
      "step": 10000
    },
    {
      "epoch": 0.7168713180495422,
      "grad_norm": 0.671513557434082,
      "learning_rate": 1.4181276172900845e-05,
      "loss": 0.1789,
      "step": 10100
    },
    {
      "epoch": 0.7239690538718149,
      "grad_norm": 1.0982426404953003,
      "learning_rate": 1.3826389381787211e-05,
      "loss": 0.223,
      "step": 10200
    },
    {
      "epoch": 0.7310667896940876,
      "grad_norm": 1.0973761081695557,
      "learning_rate": 1.3471502590673576e-05,
      "loss": 0.1977,
      "step": 10300
    },
    {
      "epoch": 0.7381645255163602,
      "grad_norm": 0.772163987159729,
      "learning_rate": 1.3116615799559942e-05,
      "loss": 0.1917,
      "step": 10400
    },
    {
      "epoch": 0.7452622613386329,
      "grad_norm": 0.7306451797485352,
      "learning_rate": 1.2765277876357443e-05,
      "loss": 0.1771,
      "step": 10500
    },
    {
      "epoch": 0.7523599971609056,
      "grad_norm": 0.9691450595855713,
      "learning_rate": 1.2410391085243808e-05,
      "loss": 0.2026,
      "step": 10600
    },
    {
      "epoch": 0.7594577329831783,
      "grad_norm": 1.1837146282196045,
      "learning_rate": 1.2055504294130173e-05,
      "loss": 0.1821,
      "step": 10700
    },
    {
      "epoch": 0.7665554688054511,
      "grad_norm": 0.694989800453186,
      "learning_rate": 1.1700617503016537e-05,
      "loss": 0.1784,
      "step": 10800
    },
    {
      "epoch": 0.7736532046277238,
      "grad_norm": 0.8018657565116882,
      "learning_rate": 1.1345730711902904e-05,
      "loss": 0.1799,
      "step": 10900
    },
    {
      "epoch": 0.7807509404499965,
      "grad_norm": 0.7068634033203125,
      "learning_rate": 1.0990843920789269e-05,
      "loss": 0.1884,
      "step": 11000
    },
    {
      "epoch": 0.7878486762722692,
      "grad_norm": 0.4809757471084595,
      "learning_rate": 1.0635957129675633e-05,
      "loss": 0.193,
      "step": 11100
    },
    {
      "epoch": 0.7949464120945419,
      "grad_norm": 0.6141923069953918,
      "learning_rate": 1.0281070338561998e-05,
      "loss": 0.1958,
      "step": 11200
    },
    {
      "epoch": 0.8020441479168146,
      "grad_norm": 0.788826584815979,
      "learning_rate": 9.926183547448365e-06,
      "loss": 0.1901,
      "step": 11300
    },
    {
      "epoch": 0.8091418837390872,
      "grad_norm": 0.6517077088356018,
      "learning_rate": 9.57129675633473e-06,
      "loss": 0.1723,
      "step": 11400
    },
    {
      "epoch": 0.8162396195613599,
      "grad_norm": 0.41851845383644104,
      "learning_rate": 9.216409965221096e-06,
      "loss": 0.1891,
      "step": 11500
    },
    {
      "epoch": 0.8233373553836326,
      "grad_norm": 0.8251794576644897,
      "learning_rate": 8.861523174107459e-06,
      "loss": 0.187,
      "step": 11600
    },
    {
      "epoch": 0.8304350912059053,
      "grad_norm": 1.5084577798843384,
      "learning_rate": 8.506636382993826e-06,
      "loss": 0.1975,
      "step": 11700
    },
    {
      "epoch": 0.837532827028178,
      "grad_norm": 0.7494555115699768,
      "learning_rate": 8.15174959188019e-06,
      "loss": 0.2183,
      "step": 11800
    },
    {
      "epoch": 0.8446305628504507,
      "grad_norm": 1.515230417251587,
      "learning_rate": 7.796862800766557e-06,
      "loss": 0.1832,
      "step": 11900
    },
    {
      "epoch": 0.8517282986727234,
      "grad_norm": 0.4813763201236725,
      "learning_rate": 7.441976009652921e-06,
      "loss": 0.18,
      "step": 12000
    },
    {
      "epoch": 0.8588260344949961,
      "grad_norm": 0.521775484085083,
      "learning_rate": 7.087089218539286e-06,
      "loss": 0.1802,
      "step": 12100
    },
    {
      "epoch": 0.8659237703172687,
      "grad_norm": 0.7360434532165527,
      "learning_rate": 6.732202427425652e-06,
      "loss": 0.1863,
      "step": 12200
    },
    {
      "epoch": 0.8730215061395414,
      "grad_norm": 0.7461637854576111,
      "learning_rate": 6.377315636312018e-06,
      "loss": 0.1835,
      "step": 12300
    },
    {
      "epoch": 0.8801192419618142,
      "grad_norm": 0.716615617275238,
      "learning_rate": 6.022428845198382e-06,
      "loss": 0.1868,
      "step": 12400
    },
    {
      "epoch": 0.8872169777840869,
      "grad_norm": 0.8228227496147156,
      "learning_rate": 5.667542054084747e-06,
      "loss": 0.1945,
      "step": 12500
    },
    {
      "epoch": 0.8943147136063596,
      "grad_norm": 0.8437544703483582,
      "learning_rate": 5.312655262971113e-06,
      "loss": 0.176,
      "step": 12600
    },
    {
      "epoch": 0.9014124494286323,
      "grad_norm": 1.191323161125183,
      "learning_rate": 4.961317339768614e-06,
      "loss": 0.1995,
      "step": 12700
    },
    {
      "epoch": 0.908510185250905,
      "grad_norm": 0.7468650341033936,
      "learning_rate": 4.606430548654979e-06,
      "loss": 0.1896,
      "step": 12800
    },
    {
      "epoch": 0.9156079210731777,
      "grad_norm": 0.7469390034675598,
      "learning_rate": 4.251543757541345e-06,
      "loss": 0.2037,
      "step": 12900
    },
    {
      "epoch": 0.9227056568954504,
      "grad_norm": 1.39115571975708,
      "learning_rate": 3.89665696642771e-06,
      "loss": 0.1748,
      "step": 13000
    },
    {
      "epoch": 0.929803392717723,
      "grad_norm": 1.2464498281478882,
      "learning_rate": 3.5417701753140748e-06,
      "loss": 0.1908,
      "step": 13100
    },
    {
      "epoch": 0.9369011285399957,
      "grad_norm": 0.8601260781288147,
      "learning_rate": 3.1868833842004404e-06,
      "loss": 0.2018,
      "step": 13200
    },
    {
      "epoch": 0.9439988643622684,
      "grad_norm": 0.7152315974235535,
      "learning_rate": 2.831996593086805e-06,
      "loss": 0.188,
      "step": 13300
    },
    {
      "epoch": 0.9510966001845411,
      "grad_norm": 1.5199295282363892,
      "learning_rate": 2.4771098019731704e-06,
      "loss": 0.187,
      "step": 13400
    },
    {
      "epoch": 0.9581943360068138,
      "grad_norm": 1.3780090808868408,
      "learning_rate": 2.1222230108595356e-06,
      "loss": 0.1858,
      "step": 13500
    },
    {
      "epoch": 0.9652920718290865,
      "grad_norm": 0.6108679175376892,
      "learning_rate": 1.767336219745901e-06,
      "loss": 0.194,
      "step": 13600
    },
    {
      "epoch": 0.9723898076513592,
      "grad_norm": 0.9373664855957031,
      "learning_rate": 1.4124494286322664e-06,
      "loss": 0.1958,
      "step": 13700
    },
    {
      "epoch": 0.9794875434736319,
      "grad_norm": 0.5925265550613403,
      "learning_rate": 1.0575626375186316e-06,
      "loss": 0.1778,
      "step": 13800
    },
    {
      "epoch": 0.9865852792959046,
      "grad_norm": 0.7364853620529175,
      "learning_rate": 7.026758464049968e-07,
      "loss": 0.1893,
      "step": 13900
    },
    {
      "epoch": 0.9936830151181772,
      "grad_norm": 0.8767860531806946,
      "learning_rate": 3.477890552913621e-07,
      "loss": 0.1748,
      "step": 14000
    }
  ],
  "logging_steps": 100,
  "max_steps": 14089,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 953398402744320.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
